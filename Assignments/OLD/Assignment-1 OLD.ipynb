{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Statistical Simulation\n",
    "\n",
    "__Due date: April 12, 2018 by 10 pm__   \n",
    "__Submision: Jupyter notebook file through GauchoSpace__   \n",
    "__Late submission policy: Within 24 hours with 10% penalty. Not accepted after 24 hours__  \n",
    "__Note: This is an individual assignment__\n",
    "\n",
    "You will create a simulation. The goal is to empirically verify one statistics or probability concept or theorem. In doing so, you will use numpy arrays, sampling from various distributions, etc.\n",
    "\n",
    "State your assumptions and choices you make in your simulation setting. Describe what you are simulating as if you were explaining the statistical result to someone with computing background, but basic probability and statistics.\n",
    "\n",
    "If you are unclear what to do, pick a theorem, and show that it is correct empirically. Show all the claims is right in a probabilistic sense. Note that asymptotic results are theoretical results that you cannot unequivocally show in a simulation setting: i.e., $n\\rightarrow\\infty$.\n",
    "\n",
    "Communicate your goal, process, and results clearly into a Jupyter notebook.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- Make sure running your notebook takes no more than 2 minutes to complete\n",
    "- Focus on explaining the concepts, coding legibly, and completeness\n",
    "- We will run your code from top to bottom. Make sure it runs to completion without errors on https://jupyterhub.lsit.ucsb.edu\n",
    "\n",
    "### Book resource\n",
    "\n",
    "An excellent resource is a book titled [Simulation by Sheldon Ross](https://ucsb-primo.hosted.exlibrisgroup.com/primo-explore/fulldisplay?docid=01UCSB_ALMA51283278820003776&context=L&vid=UCSB&search_scope=default_scope&isFrbr=true&tab=default_tab&lang=en_US). Relevant materials are in Chapters 8 - 12.\n",
    "\n",
    "### 234 students\n",
    "\n",
    "The sky is the limit! You are free to simulate some probabilistic or statistical models what you find fun and exciting: Markov chains, goodness-of-fit-tests, etc.\n",
    "\n",
    "### 134 students\n",
    "\n",
    "Here are some ideas if there aren't other simulations you would like to pursue.\n",
    "\n",
    "#### Confidence intervals\n",
    "\n",
    "Simulate random observations from a selected distribution and compute the mean and variance estimates. Compare to the theoretical confidence results: i.e., the conclusion should be comparing the number of times the confidence bound is breached as compared to confidence $1-\\alpha$.\n",
    "\n",
    "#### Hypothesis testing\n",
    "\n",
    "Select a null distribution. Then select an alternate truth that is different than the null. Sample from the alternate distribution, and, for a test statistic of your choosing, test various hypotheses. Compute the theoretical and empirical type I and II errors. Compare your results.\n",
    "\n",
    "#### Likelihood ratio test\n",
    "\n",
    "From WMS (120B textbook):\n",
    "\n",
    "> __Theorem 10.2__: Let $Y_1, Y_2, \\dots, Y_n$ have a joint likelihood function $L(\\Theta)$. Let $r_0$ denote the number of free parameters that are specified by $H_0:\\Theta\\in\\Omega_0$ and let $r$ denote the number of free parameters specified by the statement $\\Theta\\in\\Omega_0$. Then, for large n, $-2\\ln(\\lambda)$ has approximately a $\\chi^2$ distribution with $r_0-r$ degrees of freedom\n",
    "\n",
    "where \n",
    "\n",
    "> $\\lambda$ is defined by $$\\lambda = \\frac{L(\\hat\\Omega_0)}{L(\\hat\\Omega)} = \\frac{\\max_{\\Theta\\in{\\Omega_0}}L(\\Theta)}{\\max_{\\Theta\\in{\\Omega}}L(\\Theta)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based off Simulation by Sheldon Ross Chapter 12.3 Gibb's Sampling**\n",
    "\n",
    "**Suppose that X and N are jointly distributed with joint density function f (x, n) defined up to a constant of proportionality\n",
    "$$f(x,n)∝ \\frac{{e^{-4x}x^n}}{{n!}} ; n∈N, x>0.$$\n",
    "Use a Gibbs sampling to estimate E[X] and Var(X). Compare with the theoretical values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Find theoretical values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\alpha = {\\sum_{n=1}^{\\infty}\\int_0^\\infty {\\frac{x^ne^{-4x}}{n!}}dx}^{-1}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\alpha = (\\frac{1}{3}-\\frac{1}{4})^{-1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\alpha = 12$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Marginal Density of X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x) = \\sum_{n=1}^{\\infty} \\frac{x^ne^{-4x}}{n!}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x) = 12(e^{-3x}-e^{-4x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Expected Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E[X] = \\int_0^\\infty \\mathrm{xf(x)} \\mathrm{d}x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ E[X] = \\int_0^\\infty \\mathrm{12x(e^{-3x}-e^{-4x})} \\mathrm{d}x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E[X] = \\frac{7}{12}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Var[X] = E[X^2] - E[X]^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E[X^2] = \\int_0^\\infty \\mathrm{x^2f(x)} \\mathrm{d}x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ E[X^2] = \\int_0^\\infty \\mathrm{12x^2(e^{-3x}-e^{-4x})} \\mathrm{d}x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E[X^2] = \\frac{37}{72}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E[X]^2 = \\frac{49}{144}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Var[X] = \\frac{37}{72} - \\frac{49}{144}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Var[X] = \\frac{25}{144}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E[X] = .583333$$\n",
    "$$Var[X] = .1736111$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Run Gibbs Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional Distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional Distribution of X, given N = n       \n",
    "      \n",
    "$$\\frac{4^{n+1}x^ne^{-4x}}{\\Gamma(n+1)}$$\n",
    "\n",
    "This follows the gamma distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional Distribution of N, given X = x    \n",
    "       \n",
    "$$\\frac{x^n}{n!(e^x-1)}$$\n",
    "\n",
    "This is an untraditional poisson distribution because n > 0 and not n $\\ge$0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ends up looking like:   \n",
    "$$\\frac{e^{-x}}{(1-e^{-x})x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated expected value of X is: 0.5862299431038772\n",
      "This is very similar to the theoretical mean of .583333.\n",
      "The estimated variance of X is: 0.17776303002971744\n",
      "This is very similar the the theoretical variance of .1736111.\n"
     ]
    }
   ],
   "source": [
    "trials = 10000\n",
    "def gibb_Accept(x):\n",
    "    k = 1\n",
    "    t = np.exp(-x)/(1-np.exp(-x))*x\n",
    "    s = t\n",
    "    u = np.random.random(1)\n",
    "    while (s<u):\n",
    "        k += 1\n",
    "        t = t*x/k\n",
    "        s += t\n",
    "    return k\n",
    "\n",
    "def gibb(x,n,k):\n",
    "    x = np.random.gamma(shape = (n+1),scale = 1/4)\n",
    "    n = gibb_Accept(x)\n",
    "    return (x,n)\n",
    "\n",
    "#Arbritary numbers\n",
    "x = .5\n",
    "n = 1.0\n",
    "\n",
    "x_means = 0\n",
    "n_means = 0\n",
    "a = []\n",
    "\n",
    "for i in range(trials):\n",
    "    [x,n] = gibb(x,n,i)\n",
    "    x_means += x\n",
    "    a.append(x)\n",
    "    \n",
    "print(\"The estimated expected value of X is: {}\\nThis is very similar to the theoretical mean of .583333.\".format(np.mean(a)))\n",
    "print(\"The estimated variance of X is: {}\\nThis is very similar the the theoretical variance of .1736111.\".format(np.var(a)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
